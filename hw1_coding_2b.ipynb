{"cells":[{"cell_type":"markdown","metadata":{"id":"Valt8Aou0Vo5"},"source":["# CMU auto-graded notebook\n","\n","Before you turn these assignments in, make sure everything runs as expected. First, **restart the kernel** (in the menubar, select Kernel$\\rightarrow$Restart) and then **run all cells** (in the menubar, select Cell$\\rightarrow$Run All).\n","\n","Make sure you fill in any place that says `YOUR CODE HERE`, `<FILL IN>`, or \"YOUR ANSWER HERE.\"\n","\n","# CMU Machine Learning with Large Datasets\n","## Homework 1 - Coding 3: Naive Bayes with Spark"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"689500d1-213b-4e87-8f26-61421bdff2df","showTitle":false,"tableResultSettingsMap":{},"title":""},"id":"0YLcvmtv0Vo6","outputId":"282a8006-b828-4b67-ba6a-b377443b4e62"},"outputs":[{"data":{"text/html":["<style scoped>\n","  .ansiout {\n","    display: block;\n","    unicode-bidi: embed;\n","    white-space: pre-wrap;\n","    word-wrap: break-word;\n","    word-break: break-all;\n","    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n","    font-size: 13px;\n","    color: #555;\n","    margin-left: 4px;\n","    line-height: 19px;\n","  }\n","</style>"]},"metadata":{"application/vnd.databricks.v1+output":{"arguments":{},"data":"","errorSummary":"Cancelled","errorTraceType":"html","metadata":{},"type":"ipynbError"}},"output_type":"display_data"}],"source":["# Who did you collaborate with on this assignment?\n","# if no one, collaborators should contain an empty string,\n","# else list your collaborators below\n","\n","# collaborators = [\"\"]\n","# YOUR CODE HERE\n","raise NotImplementedError()"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"a1c8096b-f7b5-4c0c-b239-42686dccd2df","showTitle":false,"tableResultSettingsMap":{},"title":""},"id":"5ieSU9PN0Vo6","outputId":"5954a3e3-08ab-4f25-dbef-725aa4240f29"},"outputs":[{"data":{"text/html":["<style scoped>\n","  .ansiout {\n","    display: block;\n","    unicode-bidi: embed;\n","    white-space: pre-wrap;\n","    word-wrap: break-word;\n","    word-break: break-all;\n","    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n","    font-size: 13px;\n","    color: #555;\n","    margin-left: 4px;\n","    line-height: 19px;\n","  }\n","</style>"]},"metadata":{"application/vnd.databricks.v1+output":{"arguments":{},"data":"","errorSummary":"Cancelled","errorTraceType":"html","metadata":{},"type":"ipynbError"}},"output_type":"display_data"}],"source":["try:\n","    collaborators\n","except:\n","    raise AssertionError(\"you did not list your collaborators, if any\")"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"380470ab-c101-4304-b7ae-1bc0c9afa629","showTitle":false,"tableResultSettingsMap":{},"title":""},"id":"lQGyJMDz0Vo6","outputId":"2167efe1-2f07-4bce-e898-3efbd125fef3"},"outputs":[{"data":{"text/html":["<style scoped>\n","  .ansiout {\n","    display: block;\n","    unicode-bidi: embed;\n","    white-space: pre-wrap;\n","    word-wrap: break-word;\n","    word-break: break-all;\n","    font-family: \"Menlo\", \"Monaco\", \"Consolas\", \"Ubuntu Mono\", \"Source Code Pro\", monospace;\n","    font-size: 13px;\n","    color: #555;\n","    margin-left: 4px;\n","    line-height: 19px;\n","  }\n","</style>"]},"metadata":{"application/vnd.databricks.v1+output":{"arguments":{},"data":"","errorSummary":"Cancelled","errorTraceType":"html","metadata":{},"type":"ipynbError"}},"output_type":"display_data"}],"source":["# YOU CAN MOST LIKELY IGNORE THIS CELL. This is only of use for running this notebook locally.\n","\n","# THIS CELL DOES NOT NEED TO BE RUN ON DATABRICKS.\n","# Note that Databricks already creates a SparkContext for you, so this cell can be skipped.\n","\n","import pyspark\n","from pyspark.sql import SparkSession, SQLContext\n","\n","spark = SparkSession.builder \\\n","    .appName(\"hw\") \\\n","    .config(\"spark.ui.showConsoleProgress\", \"False\") \\\n","    .getOrCreate()\n","\n","sc = spark.sparkContext\n","sc.setLogLevel(\"OFF\")\n","sqlContext = SQLContext(sc)\n","\n","print(\"spark context started\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wZrw1REdkHbQ"},"outputs":[],"source":["import re\n","from pyspark import SparkFiles\n","from collections import Counter\n","import numpy as np"]},{"cell_type":"markdown","metadata":{"id":"fTayMIdm0Vo7"},"source":["## Enviroment Setup"]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"60fa6bc3-0adf-40e2-9b9f-f5d6d029b873","showTitle":false,"tableResultSettingsMap":{},"title":""},"id":"BIPaSX8Q0Vo7"},"source":["### (1a) Pick your data sample\n","All testing functionality is written for the `tiny` data sample. All assertions will fail if you do not use this subsample.\n","\n","**IMPORTANT NOTE**: All local test cases are meant to be run using the `tiny` data sample. If you select a data sample other than the `tiny` sample, the local tests **will not pass**."]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"6ca9f5ec-9215-4100-af7f-3f4dea921f51","showTitle":false,"tableResultSettingsMap":{},"title":""},"id":"M_QW78fR0Vo7"},"outputs":[],"source":["data_sample = 'tiny'  # 'tiny', 'smaller', 'small', 'medium', 'large', 'full'\n","\n","def get_urls(data_sample):\n","    if data_sample == 'tiny':\n","        return [\"6e7jq8igkgcsjlxjs16r9q1s5cn6rhbo\",\n","                \"rys1y8u5q9xvsnehiblx39xxd9peldbf\"]\n","\n","    elif data_sample == 'smaller':\n","        return [\"tzneue2l2trpxa7eba30fc8gqy851wjw\",\n","                \"yc9hq3qg12c456t1b9utpjkhy1mg8wy5\"]\n","\n","    elif data_sample == 'small':\n","        return [\"axx40czn6t9yx4m09y5el9xe5ke3tc4m\",\n","                \"wwopvxqhhkqpa020rwarpofr5a1gs3xg\"]\n","\n","    elif data_sample == 'medium':\n","        return [\"5n8z4a9zgx3c0mfeb2si03gh30nliflj\",\n","                \"qvklaetsx8jczya65h3kp6975q5a6s7y\"]\n","\n","    elif data_sample == 'large':\n","        return [\"2j5jx2u6tmd0nvkpw9r6d73b1u0k0vhm\",\n","                \"ekue74d3ek402liye9apuwv3rymy68dm\"]\n","\n","    elif data_sample == 'full':\n","        return [\"y3oxd7k0qybfrbqxozz1fbmdeguyfetf\",\n","                \"ejaylm39bf20arnudovzc6u268qqzw53\"]\n","\n","    else:\n","        raise ValueError(f\"Unknown data sample: {data_sample}\")\n","\n","all_labels = ['Agent', 'other', 'Event', 'ChemicalSubstance', 'Location', 'TimePeriod',\n","              'Device', 'Person','Place', 'Work', 'SportsSeason', 'Organisation',\n","              'Species', 'Activity', 'MeanOfTransportation', 'CelestialBody', 'Biomolecule']\n","\n","urls = get_urls(data_sample)"]},{"cell_type":"markdown","metadata":{"id":"p7peiFsn0Vo8"},"source":["### (1b) Parsing the raw data\n","\n","In this part, you'll load the training dataset and preprocess it into a format suitable for training a Naive Bayes classifier. Each line contains a document, its labels, and its content. Use the `parse_line` function to convert each line into `(labels, tokens)` tuples, where `labels` is a list of labels and `tokens` is a list of words from the document.\n","\n","Your task is to integrate `parse_line` into the provided Spark code to prepare the data for model training."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"72xWw1Ko0Vo8"},"outputs":[],"source":["def tokenizeDoc(curr_doc: str):\n","    \"\"\"\n","    Tokenizes the given document string into a list of words.\n","\n","    Args:\n","        curr_doc (str): The input document as a string.\n","\n","    Returns:\n","        list: A list of words (tokens) extracted from the document.\n","    \"\"\"\n","    return re.findall(r'\\w+', curr_doc)\n","\n","# TODO: Implement this function\n","def parse_line(line: str):\n","    \"\"\"\n","    Parses a single line of the dataset into labels and tokens.\n","\n","    The input line is expected to be tab-separated, with the format:\n","    <doc_id>\\t<labels>\\t<document_content>\n","\n","    Args:\n","        line (str): A single line from the dataset.\n","\n","    Returns:\n","        tuple: A tuple containing:\n","            - doc_id (str)        : The document ID\n","            - labels (list of str): List of labels for the document.\n","            - tokens (list of str): List of word tokens in the document.\n","    \"\"\"\n","    # Hint 1: Use line.split('\\t') to separate the document ID, labels, and content.\n","    # Hint 2: Use labels.split(\",\") to turn the label string into a list of labels.\n","    # Hint 3: Use tokenizeDoc(doc_words) to tokenize the document content.\n","\n","    # Remove this line and implement the function\n","    raise NotImplementedError(\"You need to implement this function!\")\n","\n","# Load the training data\n","train_url = \"https://cmu.box.com/shared/static/\" + urls[1]\n","train_filename = urls[1]\n","sc.addFile(train_url)\n","train_rdd = sc.textFile(\"file://\" + SparkFiles.get(train_filename))\n","\n","# Process each line of the dataset using the `parse_line` function\n","train_rdd = train_rdd.map(parse_line)\n","\n","# Remove the document ID for training\n","train_rdd = train_rdd.map(lambda x: x[1:])"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"42defb05-2bdc-48fc-b97e-d07862633df3","showTitle":false,"tableResultSettingsMap":{},"title":""},"id":"VMAUn4Il0Vo8"},"outputs":[],"source":["# Check if you correctly implemented the data parsing\n","# Note: This is meant to be tested on the 'tiny' data sample\n","first_sample = train_rdd.take(1)[0]\n","assert(first_sample[0][0] == 'Person')\n","assert(first_sample[1][:5] == ['abd', 'allah', 'ibn', 'amr', 'ibn'])\n","assert(len(first_sample[1]) == 169)"]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"199a746b-c074-4325-b5bc-35d670adca52","showTitle":false,"tableResultSettingsMap":{},"title":""},"id":"sTbZlTcV0Vo9"},"source":["## 2. Training the Naive Bayes Classifier\n","\n","### (2a) Compute vocabulary length\n","\n","In this step, you will compute the vocabulary size, which represents the number of unique tokens across the entire dataset. This is crucial for calculating conditional probabilities in the Naive Bayes model.\n","\n","As a reminder, the data in `train_rdd` has the following schema for each line:\n","- Each line is a tuple containing:\n","    - `labels`: A list of class labels (e.g., `['label1', 'label2']`)\n","    - `tokens`: A list of words (e.g., `['word1', 'word2', 'word3']`)\n","\n","To compute the vocabulary size, you need to flatten the tokens from all documents into a single RDD, then count the distinct tokens using `distinct()` and `count()`."]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"d6d59f70-ec38-4212-a9d8-ad680b1e92ee","showTitle":false,"tableResultSettingsMap":{},"title":""},"id":"BFjKT1Uw0Vo_"},"outputs":[],"source":["# Flatten the tokens from all documents into a single RDD, this can be done in a single line\n","vocabulary = train_rdd.<YOUR CODE HERE>\n","\n","# Compute the distinct token count (vocabulary size), can also be done in a single line\n","vocabulary_size = vocabulary.<YOUR CODE HERE>\n"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"a956e34d-6f81-4dff-9079-48892b8b611c","showTitle":false,"tableResultSettingsMap":{},"title":""},"id":"sYD5Y4A-0Vo_"},"outputs":[],"source":["assert(vocabulary_size == 28762)"]},{"cell_type":"markdown","metadata":{"id":"gwvMBKTq1jJQ"},"source":["### (2b) Compute the remainder of your model\n","\n","Now that you have completed computing the vocabulary lenght, you will need to re-implement the remainder of your Naive Bayes model in a scalable way using Spark."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JwGzqlES2DVg"},"outputs":[],"source":["# TODO: Implement Naive Bayes using Spark"]},{"cell_type":"markdown","metadata":{"id":"O-iy5vOQkHbW"},"source":["%md\n","To test your model, please extract the following variables from your model and use the cell below to ensure that your model is correct."]},{"cell_type":"code","source":["# Count of the label \"Event\" in the tiny dataset\n","freq_event = ...\n","# Count of the label \"Work\" in the tiny dataset\n","freq_work = ...\n","# Count of the label \"Person\" in the tiny dataset\n","freq_person = ..\n","# Total number of labels in the dataset\n","labels = ...\n","# Count of the label \"amr\" with label \"Person\" in the tiny dataset\n","freq_amr_given_person = ...\n","# Count of the label \"the\" with label \"Person\" in the tiny dataset\n","freq_the_given_person = ...\n","# Count of the label \"british\" with label \"Organisation\" in the tiny dataset\n","freq_british_given_org = ...\n","# Count of the label \"district\" with label \"Place\" in the tiny dataset\n","freq_district_given_place = ...\n","# Count of tokens with the label \"Event\" in the tiny dataset\n","event_tokens = ...\n","# Count of tokens with the label \"Person\" in the tiny dataset\n","person_tokens = ...\n","# Count of tokens with the label \"Work\" in the tiny dataset\n","work_tokens = ..."],"metadata":{"id":"RyyxJY96HLhg"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dosoymnzkHbX"},"outputs":[],"source":["## Test the count of each label in the dataset\n","assert(freq_event == 34)\n","assert(freq_work == 274)\n","assert(freq_person == 849)\n","## Test the total number of labels in the dataset\n","assert(labels == 2589)\n","## Test the count of each token given a label\n","assert(freq_amr_given_person == 7)\n","assert(freq_the_given_person == 4544)\n","assert(freq_british_given_org == 11)\n","assert(freq_district_given_place == 260)\n","## Test the count of tokens for each label\n","assert(event_tokens == 3083)\n","assert(person_tokens == 77993)\n","assert(work_tokens == 24024)"]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"a900c9b2-62de-4103-bfa1-6424d8237f1f","showTitle":false,"tableResultSettingsMap":{},"title":""},"id":"aCLPSmxC0VpA"},"source":["## 3. Testing the model\n","Run the following cell to load the test data. If you correctly implemented the `parse_line` function, this should work just fine."]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"8db33a5e-845b-4c23-b41f-acdd2327daca","showTitle":false,"tableResultSettingsMap":{},"title":""},"id":"cJB9qSH60VpA"},"outputs":[],"source":["test_url = \"https://cmu.box.com/shared/static/\" + urls[0]\n","test_filename = urls[0]\n","sc.addFile(test_url)\n","test_rdd = sc.textFile(\"file:///\" + SparkFiles.get(test_filename))\n","test_rdd = test_rdd.map(parse_line)"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"52a47e45-cf85-449f-8a72-228e373fd97d","showTitle":false,"tableResultSettingsMap":{},"title":""},"id":"4EqF0ylz0VpA"},"outputs":[],"source":["first_sample = test_rdd.filter(lambda x: x[0] == \"2005_UEFA_Women's_Cup_Final\").collect()[0][1:]\n","assert(first_sample[0][0] == 'Event')\n","assert(first_sample[1][:5] == ['the','2005','uefa','womens','cup',])\n","assert(len(first_sample[1]) == 36)"]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"f6007ae7-26d7-4fa8-9659-1d6cc9162c74","showTitle":false,"tableResultSettingsMap":{},"title":""},"id":"hVHJtYLI0VpA"},"source":["### (3a) Generating predictions\n","\n","In this step, you will generate predictions on the test dataset.\n","\n","Make sure you:\n","- Implement the loop that iterates over all labels and tokens.\n","- Use Laplace smoothing when calculating `P(w|y)` with alpha value of 1 as you did in the previous notebook.\n","\n","You should output an RDD `output` where each element looks like `[doc_ID, true_labels, predictd_label, max_log_prob]`."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"yX8O_e7dchFW"},"outputs":[],"source":["# TODO: Generate Predictions"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"4ef551c2-cf84-42ef-8fa9-07a19b37cdf7","showTitle":false,"tableResultSettingsMap":{},"title":""},"id":"ICK3El8k0VpB"},"outputs":[],"source":["# Get first two predictions by filtering for their document ID, then extracting their true labels, predicted label, and max log probability.\n","first_pred = output.filter(lambda x: x[0] == \"2005_UEFA_Women's_Cup_Final\").collect()[0][1:]\n","second_pred = output.filter(lambda x: x[0] == \"Armand_L%C3%A9on_de_Baudry_d'Asson\").collect()[0][1:]\n","\n","epsilon = 1e-3\n","\n","assert(first_pred[:2] == [['Event'], 'Person'])\n","assert(abs(first_pred[2] + 275.095) < epsilon)\n","\n","assert(second_pred[:2] == [['Person', 'other'], 'Person'])\n","assert(abs(second_pred[2] + 228.391) < epsilon)"]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"b910769d-cf7a-4de0-ab01-444dbc83019e","showTitle":false,"tableResultSettingsMap":{},"title":""},"id":"J2c46nGd0VpB"},"source":["### (3b) Checking accuracy\n","\n","Now, you will implement the `check_prediction` function to calculate the accuracy of the Naive Bayes model. This function checks whether the predicted label for a document matches any of the true labels.\n","\n","The `check_prediction` function takes a tuple containing:\n","\n","- `labels`: The true labels for the document.\n","- `prediction`: The predicted label for the document.\n","- A third value, which is the log probability, that you don’t need to use in this function.\n","If the predicted label matches any of the true labels, return 1. Otherwise, return 0.\n","\n","After implementing this function, you will use map to apply it to each row of the output, where each row contains the true labels, predicted label, and log probability.\n","\n","Next, compute:\n","- `total_test_samples`: The total number of test samples (the number of rows in the output).\n","- `total_correct_samples`: The number of correct predictions (the sum of the values returned by check_prediction).\n","\n","Note: The RDD `output` containing the predictions should have been computed in the last part"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"22bb06f6-1087-4bdc-8411-2368e9301414","showTitle":false,"tableResultSettingsMap":{},"title":""},"id":"lY0FzX2g0VpB"},"outputs":[],"source":["# TODO: Implement the function to check the accuracy of predictions\n","\n","def check_prediction(row):\n","    \"\"\"\n","    Checks if the predicted label matches any of the true labels.\n","\n","    Args:\n","        row (tuple): A tuple containing the doc_id, true labels, predicted label, and log probability.\n","\n","    Returns:\n","        int: 1 if the prediction is correct, 0 otherwise.\n","    \"\"\"\n","    labels, prediction, _ = row\n","\n","    # TODO: Implement logic to check if the prediction is correct\n","    raise NotImplementedError\n","\n","# Apply the check_prediction function to each row in the output\n","output = output.map(check_prediction)\n","\n","# TODO: Compute total_test_samples and total_correct_samples, both of these are one-liners.\n","total_test_samples = <YOUR CODE HERE>\n","total_correct_samples = <YOUR CODE HERE>\n","\n","accuracy = total_correct_samples / total_test_samples * 100\n","print(f\"Accuracy: {accuracy:.3f}%\")"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"b2a2a096-f6c8-40cc-a531-7ee5e8a60b08","showTitle":false,"tableResultSettingsMap":{},"title":""},"id":"tObpxkJD0VpB"},"outputs":[],"source":["epsilon = 1e-3\n","assert(abs(accuracy - 82.288) < epsilon)"]},{"cell_type":"markdown","metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{},"inputWidgets":{},"nuid":"29b22149-85e7-494a-a586-12ad7e062e5a","showTitle":false,"tableResultSettingsMap":{},"title":""},"id":"pWIT7c7e0VpB"},"source":["## 4. Top 10 words per label\n","\n","In this task, you will write code that identifies the top 10 most frequent tokens for each label. This is useful for analyzing which words are most characteristic of each class.\n","\n","Your result must be a dictionary where the keys are labels, and the values are lists of tuples of `(token, frequency)` sorted such that the first element is the most frequent token, the second is the next most, and so on.\n","\n","Store your result in the `result` variable.\n","\n","Hint: Think about how you calculated `y_w`, which is the frequency of each token given a label. You might want to re-use some code from that section, and think about what other map and reduce operations could you add onto that computation to get the top 10 most frequent words?"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c0uc2WJa4CYO"},"outputs":[],"source":["# TODO: get the top 10 words per label"]},{"cell_type":"code","execution_count":null,"metadata":{"application/vnd.databricks.v1+cell":{"cellMetadata":{"byteLimit":2048000,"rowLimit":10000},"inputWidgets":{},"nuid":"bf0cfd2e-165e-4f9e-9865-7701fe6311af","showTitle":false,"tableResultSettingsMap":{},"title":""},"id":"UhMB0FRS0VpC"},"outputs":[],"source":["assert(result['Organisation'][:5] == [(872, 'the'), (459, 'in'), (433, 'and'), (410, 'of'), (247, 'a')])\n","assert(result['Person'][:5] == [(4544, 'the'), (2838, 'in'), (2716, 'of'), (2504, 'and'), (1862, 'a')])"]},{"cell_type":"markdown","metadata":{"id":"FxYhf2QTkHba"},"source":["## 5. Train and test on large dataset\n","If you have passed all local tests, you are now ready to train and test your model on the `large` dataset. Run the following cell to load the `large` training and test RDDs."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VvSo8GpPkHba"},"outputs":[],"source":["data_sample = 'large'\n","urls = get_urls(data_sample)\n","\n","# Load the training data\n","train_url = \"https://cmu.box.com/shared/static/\" + urls[1]\n","train_filename = urls[1]\n","sc.addFile(train_url)\n","train_rdd = sc.textFile(\"file://\" + SparkFiles.get(train_filename))\n","train_rdd = train_rdd.map(parse_line)\n","train_rdd = train_rdd.map(lambda x: x[1:])\n","\n","# Load the test data\n","test_url = \"https://cmu.box.com/shared/static/\" + urls[0]\n","test_filename = urls[0]\n","sc.addFile(test_url)\n","test_rdd = sc.textFile(\"file:///\" + SparkFiles.get(test_filename))\n","test_rdd = test_rdd.map(parse_line)"]},{"cell_type":"markdown","metadata":{"id":"srqU-P9ZkHba"},"source":["Here, you will implement your training and testing functionality. Your final result should be an RDD `output` where each line has the form `[doc_ID, true_labels, predictd_label, max_log_prob]`."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"S0paRgAnkHbb"},"outputs":[],"source":["# TODO: Implement your training and testing functionality and generate predictions"]},{"cell_type":"markdown","metadata":{"id":"HBypOg_gkHbb"},"source":["After training and creating the `output` RDD from the test data, we convert `output` from an RDD to a Spark DataFrame and call `display` to see the entries. Once this cell runs, you should download the df as a `.csv` by clicking on the dropdown next to Table in the top left and select 'Download all rows. This will re-run the cell, and then download a file `export.csv` to your local machine. This what you will upload to Gradescope so make sure you store it somewhere accessible."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xa_BEMPPkHbb"},"outputs":[],"source":["# Ensure max_log_probability is a float\n","result = output.map(lambda x: (x[0], x[1], x[2], float(x[3])))\n","\n","# Convert to DF\n","result_df = result.toDF()\n","\n","# Display DF\n","display(result_df)"]}],"metadata":{"application/vnd.databricks.v1+notebook":{"computePreferences":null,"dashboards":[],"environmentMetadata":{"base_environment":"","client":"1"},"language":"python","notebookMetadata":{"pythonIndentUnit":4},"notebookName":"Testing HW1","widgets":{}},"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}